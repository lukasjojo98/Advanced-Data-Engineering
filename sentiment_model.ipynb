{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ZhJBByG4Ju",
        "outputId": "1ffb6eee-340c-4382-a79c-63cc33f79c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.mllib.feature import HashingTF\n",
        "from pyspark.mllib.regression import LabeledPoint\n",
        "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IVRIMZhIM-ED"
      },
      "outputs": [],
      "source": [
        "# 1. Initialize Spark Session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Sentiment Analysis with JSON Data\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# 2. Load JSON Data\n",
        "load_dotenv(\"./env.env\")\n",
        "path = os.getenv(\"DATA_PATH\")\n",
        "data_df = spark.read.json(path)\n",
        "\n",
        "# 3. Select Relevant Fields\n",
        "# Filter rows with non-null \"reviewText\" and \"overall\"\n",
        "filtered_df = data_df.select(\"reviewText\", \"overall\") \\\n",
        "                     .filter(\"reviewText IS NOT NULL AND overall IS NOT NULL\")\n",
        "\n",
        "# 4. Transform DataFrame to RDD and Label Data\n",
        "# Map rows to (label, reviewText)\n",
        "data_rdd = filtered_df.rdd.map(lambda row: (\n",
        "    1.0 if row[\"overall\"] >= 4 else 0.0,  # Positive sentiment (>=4) -> 1.0, Negative -> 0.0\n",
        "    row[\"reviewText\"]\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GsbAuq9qNDoP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 5. Split Data into Training and Testing Sets\n",
        "train_rdd, test_rdd = data_rdd.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# 6. Feature Engineering with HashingTF\n",
        "hashing_tf = HashingTF(numFeatures=10000)  # 10,000-dimensional feature space\n",
        "\n",
        "def featurize_data(label, text):\n",
        "    words = text.split()  # Tokenize the review text\n",
        "    features = hashing_tf.transform(words)  # Generate feature vector\n",
        "    return LabeledPoint(label, features)\n",
        "\n",
        "# Apply feature engineering\n",
        "train_features = train_rdd.map(lambda x: featurize_data(x[0], x[1]))\n",
        "test_features = test_rdd.map(lambda x: featurize_data(x[0], x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y7gzqljNF29",
        "outputId": "1c186f02-4d61-43e6-c1f5-e254a082bcc0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/mllib/classification.py:395: FutureWarning: Deprecated in 2.0.0. Use ml.classification.LogisticRegression or LogisticRegressionWithLBFGS.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 7. Train Logistic Regression Model\n",
        "model = LogisticRegressionWithSGD.train(train_features, iterations=100)\n",
        "\n",
        "# 8. Predictions on the Test Set\n",
        "predictions_and_labels = test_features.map(lambda x: (float(model.predict(x.features)), float(x.label)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_tZQjlnNKYk",
        "outputId": "28f91c24-001f-4807-8ea7-b2c7d68bb178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.79\n",
            "Example Predictions:\n",
            "[(1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 1.0), (1.0, 0.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (0.0, 0.0)]\n"
          ]
        }
      ],
      "source": [
        "# 9. Evaluate Model Performance\n",
        "metrics = MulticlassMetrics(predictions_and_labels)\n",
        "accuracy = metrics.accuracy\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# 10. Display Example Predictions\n",
        "print(\"Example Predictions:\")\n",
        "print(predictions_and_labels.take(10))\n",
        "\n",
        "# Stop Spark Session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
