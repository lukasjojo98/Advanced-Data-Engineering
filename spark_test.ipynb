{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de213cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:18:46.246460Z",
     "start_time": "2024-12-02T13:18:46.233942Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip, os, json, time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe53901",
   "metadata": {},
   "source": [
    "## Demo without Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994a57a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:12:52.931409Z",
     "start_time": "2024-12-02T13:12:52.917882Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d0d464591602f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:18:49.299715Z",
     "start_time": "2024-12-02T13:18:49.287970Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv(\"./env.env\")\n",
    "path = os.getenv(\"DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058874d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:20:19.664874Z",
     "start_time": "2024-12-02T13:18:53.404005Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ratings = []\n",
    "for review in parse(path):\n",
    "  ratings.append(review['overall'])\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9de2310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0220948494727224\n",
      "Time taken: 22.620104 seconds\n"
     ]
    }
   ],
   "source": [
    "print(sum(ratings) / len(ratings))\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf8689",
   "metadata": {},
   "source": [
    "## Demo with Spark (Spark Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02269e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:21:55.555484Z",
     "start_time": "2024-12-02T13:21:36.484665Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/03 11:21:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AmazonReviewsAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a8ec8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:22:28.369715Z",
     "start_time": "2024-12-02T13:21:55.588174Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "reviews_df = spark.read.json(path)\n",
    "valid_reviews_df = reviews_df.filter(reviews_df.overall.isNotNull())\n",
    "average_rating = valid_reviews_df.selectExpr(\"avg(overall) as avg_rating\").collect()[0]['avg_rating']\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bf2735",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:22:28.931752Z",
     "start_time": "2024-12-02T13:22:28.377712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating: 4.0220948494727224\n",
      "Time taken: 41.305547 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Rating: {average_rating}\")\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390dca6f",
   "metadata": {},
   "source": [
    "## Demo with Spark (RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "417f3a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:23:39.209274Z",
     "start_time": "2024-12-02T13:22:55.908289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc = pyspark.SparkContext(appName=\"AdvDataEng-03-2-Spark\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rdd = sc.textFile(path)\n",
    "parsed_rdd = rdd.map(lambda line: json.loads(line))\n",
    "ratings_rdd = parsed_rdd.map(lambda review: review.get('overall')).filter(lambda x: x is not None)\n",
    "\n",
    "rating_sum = ratings_rdd.reduce(lambda x, y: x + y)\n",
    "rating_count = ratings_rdd.count()\n",
    "average_rating = rating_sum / rating_count\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6577244",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T13:23:40.194966Z",
     "start_time": "2024-12-02T13:23:39.217043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rating: 4.0220948494727224\n",
      "Time taken: 27.581993 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Rating: {average_rating}\")\n",
    "print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
